{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"kaggle_diabetes.ipynb","provenance":[{"file_id":"1KII0qotTSEl3XqQV54uH2dYyl0Fp5VWG","timestamp":1588420837504}],"collapsed_sections":[],"authorship_tag":"ABX9TyMESRsJVlThgDWwnB1igsA2"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"X8MOETAMNgsu","colab_type":"text"},"source":["## [1] kaggle 사용을 위한 setting"]},{"cell_type":"code","metadata":{"id":"sSA3-8Gm7nf0","colab_type":"code","outputId":"9d51243d-75f9-484d-ba20-7bc1bd1d8240","executionInfo":{"status":"ok","timestamp":1588479418038,"user_tz":-540,"elapsed":18193,"user":{"displayName":"Juhee","photoUrl":"","userId":"14369088239483395487"}},"colab":{"base_uri":"https://localhost:8080/","height":570}},"source":["!pip uninstall -y kaggle\n","!pip install --upgrade pip\n","!pip install kaggle==1.5.6"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Uninstalling kaggle-1.5.6:\n","  Successfully uninstalled kaggle-1.5.6\n","Collecting pip\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/2e/df11ea7e23e7e761d484ed3740285a34e38548cf2bad2bed3dd5768ec8b9/pip-20.1-py2.py3-none-any.whl (1.5MB)\n","\u001b[K     |████████████████████████████████| 1.5MB 2.8MB/s \n","\u001b[?25hInstalling collected packages: pip\n","  Found existing installation: pip 19.3.1\n","    Uninstalling pip-19.3.1:\n","      Successfully uninstalled pip-19.3.1\n","Successfully installed pip-20.1\n","Collecting kaggle==1.5.6\n","  Downloading kaggle-1.5.6.tar.gz (58 kB)\n","\u001b[K     |████████████████████████████████| 58 kB 1.7 MB/s \n","\u001b[?25hRequirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (1.24.3)\n","Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (1.12.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (2020.4.5.1)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (2.8.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (2.23.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (4.38.0)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (4.0.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle==1.5.6) (2.9)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle==1.5.6) (3.0.4)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle==1.5.6) (1.3)\n","Building wheels for collected packages: kaggle\n","  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for kaggle: filename=kaggle-1.5.6-py3-none-any.whl size=72859 sha256=cbf095646836e3e55357d0c5b6835b9a6d53bd0d6af50ec8bb642663f7d9e41f\n","  Stored in directory: /root/.cache/pip/wheels/01/3e/ff/77407ebac3ef71a79b9166a8382aecf88415a0bcbe3c095a01\n","Successfully built kaggle\n","Installing collected packages: kaggle\n","Successfully installed kaggle-1.5.6\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OEQJIYmC8YtV","colab_type":"code","outputId":"64c60032-c35e-4c41-9d01-c92b6a8e863a","executionInfo":{"status":"ok","timestamp":1588479424632,"user_tz":-540,"elapsed":24711,"user":{"displayName":"Juhee","photoUrl":"","userId":"14369088239483395487"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["!mkdir -p ~/.kaggle                   #캐글 폴더 생성\n","!cp kaggle.json ~/.kaggle/            # 폴더에 kaggle.json을 복붙하기\n","! chmod 600 ~/.kaggle/kaggle.json     # 복붙한 것의 권한을 주기\n","!kaggle -v"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Kaggle API 1.5.6\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GZdQNZ4E8rvI","colab_type":"code","outputId":"c62e2f1e-d6bb-40c8-cb7e-b156fc932ec8","executionInfo":{"status":"ok","timestamp":1588479428208,"user_tz":-540,"elapsed":28250,"user":{"displayName":"Juhee","photoUrl":"","userId":"14369088239483395487"}},"colab":{"base_uri":"https://localhost:8080/","height":141}},"source":["!kaggle competitions download -c logistic-classification-diabetes\n","\n","!unzip logistic-classification-diabetes.zip   #폴더이름.zip"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Downloading logistic-classification-diabetes.zip to /content\n","\r  0% 0.00/16.3k [00:00<?, ?B/s]\n","\r100% 16.3k/16.3k [00:00<00:00, 14.4MB/s]\n","Archive:  logistic-classification-diabetes.zip\n","  inflating: submission_form.csv     \n","  inflating: test_data.csv           \n","  inflating: train.csv               \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pcWd8fh8N70Y","colab_type":"text"},"source":["## [2] 데이터 로더"]},{"cell_type":"code","metadata":{"id":"hkhw94yr81_R","colab_type":"code","outputId":"223c32b9-f2b2-4e9d-d959-7c6ba603192b","executionInfo":{"status":"ok","timestamp":1588479430683,"user_tz":-540,"elapsed":30675,"user":{"displayName":"Juhee","photoUrl":"","userId":"14369088239483395487"}},"colab":{"base_uri":"https://localhost:8080/","height":141}},"source":["import numpy as np\n","import torch\n","import torch.optim as optim\n","import pandas as pd\n","\n","xy = np.loadtxt('train.csv', delimiter=\",\", dtype=np.float32 ,skiprows=1, usecols=range(1,10))\n","print(xy)\n","\n","\n","x_data=xy[:,0:-1]\n","y_data=xy[:,[-1]].squeeze()         # pandas_xy.loc[:,9]\n","\n","x_train = torch.FloatTensor(x_data)  \n","y_train = torch.LongTensor(y_data)  "],"execution_count":0,"outputs":[{"output_type":"stream","text":["[[-0.294118   0.487437   0.180328  ... -0.53117   -0.0333333  0.       ]\n"," [-0.882353  -0.145729   0.0819672 ... -0.766866  -0.666667   1.       ]\n"," [-0.0588235  0.839196   0.0491803 ... -0.492741  -0.633333   0.       ]\n"," ...\n"," [-0.176471   0.879397  -0.180328  ... -0.36123   -0.566667   0.       ]\n"," [-0.647059   0.738693   0.278689  ... -0.238258  -0.666667   0.       ]\n"," [ 0.176471  -0.0552764  0.180328  ... -0.558497   0.166667   1.       ]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Kz3mL6ttRf1F","colab_type":"code","outputId":"de3fc0ca-7462-4308-e925-c0e7c55efd1e","executionInfo":{"status":"ok","timestamp":1588479430685,"user_tz":-540,"elapsed":30608,"user":{"displayName":"Juhee","photoUrl":"","userId":"14369088239483395487"}},"colab":{"base_uri":"https://localhost:8080/","height":159}},"source":["print(x_train[:5])   \n","print(y_train[:5])\n","\n","print(x_train.shape)\n","print(y_train.shape)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([[-0.2941,  0.4874,  0.1803, -0.2929,  0.0000,  0.0015, -0.5312, -0.0333],\n","        [-0.8824, -0.1457,  0.0820, -0.4141,  0.0000, -0.2072, -0.7669, -0.6667],\n","        [-0.0588,  0.8392,  0.0492,  0.0000,  0.0000, -0.3055, -0.4927, -0.6333],\n","        [-0.8824, -0.1055,  0.0820, -0.5354, -0.7778, -0.1624, -0.9240,  0.0000],\n","        [ 0.0000,  0.3769, -0.3443, -0.2929, -0.6028,  0.2846,  0.8873, -0.6000]])\n","tensor([0, 1, 0, 1, 0])\n","torch.Size([709, 8])\n","torch.Size([709])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"AnIQkAhn-8II","colab_type":"text"},"source":["## [3] 모델 학습"]},{"cell_type":"code","metadata":{"id":"4eyPMFLX--db","colab_type":"code","outputId":"330a047c-4239-497b-bf49-1e355ee26699","executionInfo":{"status":"ok","timestamp":1588479438269,"user_tz":-540,"elapsed":38140,"user":{"displayName":"Juhee","photoUrl":"","userId":"14369088239483395487"}},"colab":{"base_uri":"https://localhost:8080/","height":212}},"source":["import torch.nn.functional as F  # for softmax\n","\n","#feature 8개, 2개의 클래스(0,1)\n","\n","nb_class = 2\n","nb_data = len(y_train)\n","\n","W = torch.zeros((8, nb_class), requires_grad=True)  \n","b = torch.zeros(1, requires_grad=True)\n","\n","# optimizer 설정\n","optimizer = optim.SGD([W, b], lr=0.01)   #lr=0.01\n","\n","nb_epochs = 10000               \n","for epoch in range(nb_epochs + 1):\n","\n","    # Cost 계산 (1)\n","    hypothesis = F.softmax(x_train.matmul(W) + b, dim=1) # or .mm or @\n","    \n","    # cost 표현번 1번 예시\n","      # one-hot encoding.\n","    y_one_hot = torch.zeros(nb_data, nb_class)\n","    y_one_hot.scatter_(1, y_train.unsqueeze(1), 1)\n","    cost = (y_one_hot * -torch.log(F.softmax(hypothesis, dim=1))).sum(dim=1).mean()\n","\n","\n","    # cost로 H(x) 개선 (w 업데이트)\n","    optimizer.zero_grad()\n","    cost.backward()\n","    optimizer.step()\n","\n","    # 100번마다 로그 출력\n","    if epoch % 1000 == 0:\n","        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n","            epoch, nb_epochs, cost.item()\n","        ))\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch    0/10000 Cost: 0.693147\n","Epoch 1000/10000 Cost: 0.614406\n","Epoch 2000/10000 Cost: 0.597775\n","Epoch 3000/10000 Cost: 0.586016\n","Epoch 4000/10000 Cost: 0.576891\n","Epoch 5000/10000 Cost: 0.569821\n","Epoch 6000/10000 Cost: 0.564295\n","Epoch 7000/10000 Cost: 0.559904\n","Epoch 8000/10000 Cost: 0.556352\n","Epoch 9000/10000 Cost: 0.553432\n","Epoch 10000/10000 Cost: 0.550995\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qoe0QcN_I21B","colab_type":"text"},"source":["## [4] 정답예측"]},{"cell_type":"code","metadata":{"id":"Bw67scJxcVTl","colab_type":"code","outputId":"3dfc1cce-bebf-43a0-a0a8-cee4e1c5287b","executionInfo":{"status":"ok","timestamp":1588479438271,"user_tz":-540,"elapsed":38116,"user":{"displayName":"Juhee","photoUrl":"","userId":"14369088239483395487"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# 학습된 W,b를 통한 클래스 예측\n","\n","hypothesis = F.softmax(x_train.matmul(W) + b, dim=1) # or .mm or @\n","predict = torch.argmax(hypothesis, dim=1) \n","          # torch.argmax(): hypothesis(=wx)에서 가장 큰 값의 인덱스를 return\n","\n","#print(hypothesis) # 범주형데이터로 바뀌기 전. wx를 구한 상태.\n","#print(predict)    # 예측한 클래스 \n","#print(y_train)    # 실제 데이터.\n","\n","# 정확도 계산 \n","correct_prediction = predict.float() == y_train\n","print(correct_prediction[:5])\n","\n","accuracy = correct_prediction.sum().item() / len(correct_prediction)\n","print('The model has an accuracy of {:2.2f}% for the training set.'.format(accuracy * 100))\n","\n","# lr=0.01, 에폭=1000, 정확도는 76.45%\n","# lr=0.01, 에폭 10000, 정확도는 77.15%"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([ True,  True,  True,  True,  True,  True, False,  True,  True, False,\n","         True,  True, False,  True, False,  True, False,  True, False,  True,\n","         True,  True, False, False,  True,  True,  True,  True,  True, False,\n","         True,  True,  True,  True, False, False, False, False,  True, False,\n","         True,  True, False,  True,  True,  True, False,  True,  True,  True,\n","         True,  True, False,  True,  True,  True, False,  True,  True, False,\n","         True,  True, False,  True, False,  True,  True,  True, False,  True,\n","         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n","         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n","         True, False,  True,  True,  True,  True,  True, False,  True,  True,\n","         True,  True,  True,  True,  True,  True,  True, False, False,  True,\n","         True,  True,  True,  True, False,  True,  True,  True,  True,  True,\n","         True,  True, False, False,  True,  True, False, False, False,  True,\n","        False,  True,  True,  True,  True,  True, False,  True,  True,  True,\n","         True, False,  True,  True,  True,  True, False,  True,  True,  True,\n","         True, False,  True,  True,  True,  True,  True,  True,  True,  True,\n","         True,  True,  True, False,  True,  True,  True,  True, False, False,\n","         True,  True,  True,  True,  True,  True, False,  True,  True,  True,\n","         True,  True,  True,  True,  True, False, False, False,  True,  True,\n","         True,  True,  True,  True,  True, False, False, False,  True,  True,\n","         True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n","        False, False, False,  True, False,  True, False, False,  True,  True,\n","         True,  True,  True,  True,  True,  True, False,  True,  True,  True,\n","         True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n","        False,  True,  True,  True, False,  True,  True,  True,  True,  True,\n","         True, False, False,  True,  True, False,  True, False,  True,  True,\n","        False,  True,  True,  True,  True, False,  True,  True,  True,  True,\n","         True,  True, False,  True,  True,  True,  True,  True,  True,  True,\n","        False, False, False,  True,  True,  True, False, False, False, False,\n","         True, False,  True, False,  True,  True, False,  True, False,  True,\n","         True, False,  True, False, False,  True,  True, False,  True, False,\n","         True,  True,  True,  True,  True,  True, False, False,  True,  True,\n","         True, False, False, False,  True,  True,  True,  True,  True,  True,\n","        False, False, False,  True,  True,  True,  True,  True,  True,  True,\n","         True,  True,  True,  True, False,  True,  True,  True,  True,  True,\n","         True, False,  True,  True,  True,  True, False,  True,  True,  True,\n","         True, False,  True,  True, False,  True, False,  True,  True,  True,\n","         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n","         True, False, False, False,  True,  True,  True,  True,  True,  True,\n","         True,  True, False,  True,  True, False, False,  True,  True,  True,\n","        False,  True,  True,  True,  True,  True,  True,  True, False,  True,\n","         True, False,  True, False,  True,  True,  True,  True,  True,  True,\n","         True, False,  True, False,  True,  True,  True,  True,  True,  True,\n","        False,  True,  True,  True,  True,  True,  True, False, False,  True,\n","         True,  True, False,  True,  True, False,  True,  True,  True,  True,\n","         True,  True,  True,  True,  True,  True,  True, False,  True,  True,\n","         True, False, False,  True,  True,  True,  True,  True,  True, False,\n","         True,  True,  True, False,  True,  True,  True,  True,  True,  True,\n","        False,  True, False,  True,  True,  True, False,  True, False,  True,\n","         True,  True, False,  True,  True, False,  True,  True,  True,  True,\n","         True,  True,  True, False,  True,  True,  True,  True, False,  True,\n","         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n","         True,  True,  True, False,  True,  True,  True, False,  True,  True,\n","         True, False, False, False, False,  True,  True,  True,  True,  True,\n","         True, False,  True,  True,  True,  True,  True,  True,  True,  True,\n","         True,  True, False,  True,  True,  True,  True,  True,  True,  True,\n","         True, False,  True,  True,  True,  True,  True,  True,  True, False,\n","         True,  True,  True,  True,  True,  True, False,  True,  True,  True,\n","         True,  True,  True,  True, False,  True,  True,  True,  True,  True,\n","         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n","        False,  True,  True, False,  True,  True,  True,  True,  True,  True,\n","        False, False,  True,  True, False,  True,  True,  True,  True, False,\n","         True,  True, False,  True,  True,  True,  True, False,  True,  True,\n","        False,  True,  True,  True, False,  True,  True,  True, False,  True,\n","        False,  True,  True,  True,  True,  True,  True, False,  True,  True,\n","        False, False,  True,  True,  True, False,  True, False, False,  True,\n","         True, False,  True,  True, False,  True,  True,  True,  True, False,\n","         True,  True,  True,  True, False, False,  True,  True,  True,  True,\n","        False,  True,  True,  True, False,  True, False, False,  True,  True,\n","         True,  True, False,  True,  True,  True,  True, False,  True,  True,\n","        False,  True,  True,  True,  True,  True,  True,  True,  True])\n","The model has an accuracy of 76.45% for the training set.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"x0y6g1Qgc038","colab_type":"text"},"source":["## 데이터에 대한 TEST\n","캐글의 TEST 셋을 가지고 예측값을 구하기"]},{"cell_type":"code","metadata":{"id":"gBUwYvLfIXX7","colab_type":"code","outputId":"d645884a-ed73-45c4-9562-b25a62d60687","executionInfo":{"status":"ok","timestamp":1588480736988,"user_tz":-540,"elapsed":936,"user":{"displayName":"Juhee","photoUrl":"","userId":"14369088239483395487"}},"colab":{"base_uri":"https://localhost:8080/","height":70}},"source":["# usecol=range(1,9)  10이 아님.\n","test=np.loadtxt('test_data.csv',delimiter=\",\", dtype=np.float32, skiprows=1, usecols=range(1,9))\n","\n","x_data=test     # test_data.csv 에는 라벨이 없기때문에 라벨에 관한것을 하면 오류가 뜰 것임\n","\n","x_data=np.array(x_data)\n","x_test=torch.FloatTensor(x_data)\n","\n","hypothesis=F.softmax(x_test.matmul(W) +b, dim=1)\n","predict=torch.argmax(hypothesis, dim=1)\n","predict    "],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n","        1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1,\n","        1, 1], grad_fn=<NotImplemented>)"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"rLBVYUjWJgiz","colab_type":"text"},"source":["## [5] 캐글에 제출하기\n","\n","\n","- test 데이터 셋의 포맷에 맞추기.\n","submit_sample.csv\n"]},{"cell_type":"code","metadata":{"id":"q0qBXhTpJjn8","colab_type":"code","outputId":"9bee7651-8895-464b-c6ac-36d0cc443e23","executionInfo":{"status":"ok","timestamp":1588479438273,"user_tz":-540,"elapsed":38015,"user":{"displayName":"Juhee","photoUrl":"","userId":"14369088239483395487"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import pandas as pd\n","\n","submit=pd.read_csv('submission_form.csv')\n","submit               # id와 expected의 헤더를 가지고 있다."],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>5</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>6</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>7</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>8</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>9</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>10</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>11</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>12</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>13</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>14</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>15</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>16</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>17</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>18</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>19</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>20</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>21</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>22</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>23</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>24</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>25</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>26</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>27</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>28</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>29</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>30</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>31</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>32</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>33</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>34</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>35</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>36</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td>37</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>38</th>\n","      <td>38</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>39</th>\n","      <td>39</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>40</th>\n","      <td>40</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>41</th>\n","      <td>41</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>42</th>\n","      <td>42</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>43</th>\n","      <td>43</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>44</th>\n","      <td>44</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>45</th>\n","      <td>45</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>46</th>\n","      <td>46</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>47</th>\n","      <td>47</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>48</th>\n","      <td>48</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>49</th>\n","      <td>49</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    ID  Label\n","0    0    NaN\n","1    1    NaN\n","2    2    NaN\n","3    3    NaN\n","4    4    NaN\n","5    5    NaN\n","6    6    NaN\n","7    7    NaN\n","8    8    NaN\n","9    9    NaN\n","10  10    NaN\n","11  11    NaN\n","12  12    NaN\n","13  13    NaN\n","14  14    NaN\n","15  15    NaN\n","16  16    NaN\n","17  17    NaN\n","18  18    NaN\n","19  19    NaN\n","20  20    NaN\n","21  21    NaN\n","22  22    NaN\n","23  23    NaN\n","24  24    NaN\n","25  25    NaN\n","26  26    NaN\n","27  27    NaN\n","28  28    NaN\n","29  29    NaN\n","30  30    NaN\n","31  31    NaN\n","32  32    NaN\n","33  33    NaN\n","34  34    NaN\n","35  35    NaN\n","36  36    NaN\n","37  37    NaN\n","38  38    NaN\n","39  39    NaN\n","40  40    NaN\n","41  41    NaN\n","42  42    NaN\n","43  43    NaN\n","44  44    NaN\n","45  45    NaN\n","46  46    NaN\n","47  47    NaN\n","48  48    NaN\n","49  49    NaN"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"ZqjWbXPxJ_PK","colab_type":"code","colab":{}},"source":["predict= predict.detach().numpy().reshape(-1,1)\n","\n","id=np.array([i for i in range(50)]).reshape(-1,1)\n","\n","result=np.hstack([id,predict])\n","df=pd.DataFrame(result, columns=[\"id\",\"Label\"])\n","df.to_csv('result.csv', index=False, header=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iWgFVE021MRv","colab_type":"code","outputId":"eff50ab4-78ed-4387-f17e-d9748f461e41","executionInfo":{"status":"ok","timestamp":1588480759895,"user_tz":-540,"elapsed":1403,"user":{"displayName":"Juhee","photoUrl":"","userId":"14369088239483395487"}},"colab":{"base_uri":"https://localhost:8080/","height":906}},"source":["result"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 0,  1],\n","       [ 1,  1],\n","       [ 2,  1],\n","       [ 3,  1],\n","       [ 4,  1],\n","       [ 5,  1],\n","       [ 6,  1],\n","       [ 7,  1],\n","       [ 8,  1],\n","       [ 9,  1],\n","       [10,  1],\n","       [11,  1],\n","       [12,  1],\n","       [13,  1],\n","       [14,  0],\n","       [15,  1],\n","       [16,  1],\n","       [17,  1],\n","       [18,  1],\n","       [19,  1],\n","       [20,  1],\n","       [21,  1],\n","       [22,  0],\n","       [23,  1],\n","       [24,  1],\n","       [25,  0],\n","       [26,  0],\n","       [27,  1],\n","       [28,  0],\n","       [29,  1],\n","       [30,  0],\n","       [31,  0],\n","       [32,  0],\n","       [33,  1],\n","       [34,  1],\n","       [35,  0],\n","       [36,  0],\n","       [37,  1],\n","       [38,  1],\n","       [39,  1],\n","       [40,  1],\n","       [41,  0],\n","       [42,  1],\n","       [43,  0],\n","       [44,  1],\n","       [45,  1],\n","       [46,  1],\n","       [47,  1],\n","       [48,  1],\n","       [49,  1]])"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"uHXNPGSfKVtc","colab_type":"code","outputId":"cf14aac2-b73e-4221-afd2-ecf31fdae4db","executionInfo":{"status":"ok","timestamp":1588480783936,"user_tz":-540,"elapsed":12863,"user":{"displayName":"Juhee","photoUrl":"","userId":"14369088239483395487"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["! kaggle competitions submit -c logistic-classification-diabetes -f result.csv -m 'first 16010064 이주희'"],"execution_count":0,"outputs":[{"output_type":"stream","text":["100% 249/249 [00:07<00:00, 32.3B/s]\n","Successfully submitted to logistic classification : diabetes"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Br8-_6_EK6cc","colab_type":"code","colab":{}},"source":["# kaggle의 leader보드에서 확인하기"],"execution_count":0,"outputs":[]}]}